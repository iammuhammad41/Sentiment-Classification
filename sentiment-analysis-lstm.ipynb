{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06cdf0a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-22T16:44:30.053577Z",
     "iopub.status.busy": "2025-06-22T16:44:30.053209Z",
     "iopub.status.idle": "2025-06-22T16:45:58.855649Z",
     "shell.execute_reply": "2025-06-22T16:45:58.854648Z"
    },
    "papermill": {
     "duration": 88.811674,
     "end_time": "2025-06-22T16:45:58.860219",
     "exception": false,
     "start_time": "2025-06-22T16:44:30.048545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 16:44:32.972477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750610673.308323      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750610673.400635      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv\n",
      "/kaggle/input/sentiment-analysis-dataset/train.csv\n",
      "/kaggle/input/sentiment-analysis-dataset/testdata.manual.2009.06.14.csv\n",
      "/kaggle/input/sentiment-analysis-dataset/test.csv\n",
      "/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin.gz\n",
      "/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/googlenewsvectors/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.src.layers import Embedding\n",
    "from keras.src.legacy.preprocessing.text import Tokenizer\n",
    "from keras.src.utils import pad_sequences\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import kagglehub\n",
    "import nltk\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0912ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:45:58.868089Z",
     "iopub.status.busy": "2025-06-22T16:45:58.867477Z",
     "iopub.status.idle": "2025-06-22T16:45:59.114171Z",
     "shell.execute_reply": "2025-06-22T16:45:59.113140Z"
    },
    "papermill": {
     "duration": 0.252062,
     "end_time": "2025-06-22T16:45:59.115733",
     "exception": false,
     "start_time": "2025-06-22T16:45:58.863671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f5eaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:45:59.123371Z",
     "iopub.status.busy": "2025-06-22T16:45:59.123039Z",
     "iopub.status.idle": "2025-06-22T16:45:59.350447Z",
     "shell.execute_reply": "2025-06-22T16:45:59.349467Z"
    },
    "papermill": {
     "duration": 0.233082,
     "end_time": "2025-06-22T16:45:59.352325",
     "exception": false,
     "start_time": "2025-06-22T16:45:59.119243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/train.csv', encoding='latin1')\n",
    "df_test = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/test.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0c9597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:45:59.360803Z",
     "iopub.status.busy": "2025-06-22T16:45:59.360130Z",
     "iopub.status.idle": "2025-06-22T16:45:59.364846Z",
     "shell.execute_reply": "2025-06-22T16:45:59.364098Z"
    },
    "papermill": {
     "duration": 0.010445,
     "end_time": "2025-06-22T16:45:59.366235",
     "exception": false,
     "start_time": "2025-06-22T16:45:59.355790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text.lower())  # tokenize and lowercase\n",
    "    filtered = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d7cc45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:45:59.373450Z",
     "iopub.status.busy": "2025-06-22T16:45:59.373160Z",
     "iopub.status.idle": "2025-06-22T16:46:03.654241Z",
     "shell.execute_reply": "2025-06-22T16:46:03.653375Z"
    },
    "papermill": {
     "duration": 4.2865,
     "end_time": "2025-06-22T16:46:03.655923",
     "exception": false,
     "start_time": "2025-06-22T16:45:59.369423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train[['text']]\n",
    "y_train = df_train['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})  # or binary\n",
    "df_test = df_test.dropna()\n",
    "X_test = df_test[['text']]\n",
    "y_test = df_test['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})  # Only if present\n",
    "\n",
    "# Flatten the DataFrame columns\n",
    "train_texts = X_train['text'].astype(str).apply(remove_stopwords)\n",
    "test_texts = X_test['text'].astype(str).apply(remove_stopwords)\n",
    "\n",
    "train_y = y_train.astype(int).tolist()\n",
    "test_y = y_test.astype(int).tolist()\n",
    "\n",
    "y_train_cat = to_categorical(train_y, num_classes=3)\n",
    "y_test_cat = to_categorical(test_y, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2453eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:03.663311Z",
     "iopub.status.busy": "2025-06-22T16:46:03.663018Z",
     "iopub.status.idle": "2025-06-22T16:46:04.349253Z",
     "shell.execute_reply": "2025-06-22T16:46:04.348347Z"
    },
    "papermill": {
     "duration": 0.691512,
     "end_time": "2025-06-22T16:46:04.350631",
     "exception": false,
     "start_time": "2025-06-22T16:46:03.659119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1\n",
      "good 2\n",
      "get 3\n",
      "like 4\n",
      "go 5\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "max_len = max(max(len(seq) for seq in train_sequences), 50)\n",
    "\n",
    "X_train_pad = pad_sequences(train_sequences, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(test_sequences, maxlen=max_len)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Print first 5 keys\n",
    "for key in list(word_index.keys())[:5]:\n",
    "    print(key, word_index[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77c0f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:04.358834Z",
     "iopub.status.busy": "2025-06-22T16:46:04.358030Z",
     "iopub.status.idle": "2025-06-22T16:46:04.364410Z",
     "shell.execute_reply": "2025-06-22T16:46:04.363579Z"
    },
    "papermill": {
     "duration": 0.011464,
     "end_time": "2025-06-22T16:46:04.365732",
     "exception": false,
     "start_time": "2025-06-22T16:46:04.354268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faac1506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:04.372678Z",
     "iopub.status.busy": "2025-06-22T16:46:04.372446Z",
     "iopub.status.idle": "2025-06-22T16:46:04.377499Z",
     "shell.execute_reply": "2025-06-22T16:46:04.376717Z"
    },
    "papermill": {
     "duration": 0.010023,
     "end_time": "2025-06-22T16:46:04.378834",
     "exception": false,
     "start_time": "2025-06-22T16:46:04.368811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a984fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:04.386217Z",
     "iopub.status.busy": "2025-06-22T16:46:04.385965Z",
     "iopub.status.idle": "2025-06-22T16:46:59.149042Z",
     "shell.execute_reply": "2025-06-22T16:46:59.148212Z"
    },
    "papermill": {
     "duration": 54.768594,
     "end_time": "2025-06-22T16:46:59.150668",
     "exception": false,
     "start_time": "2025-06-22T16:46:04.382074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# Build Embedding Matrix from Word2Vec\n",
    "path = kagglehub.dataset_download(\"leadbest/googlenewsvectorsnegative300\")\n",
    "path += '/GoogleNews-vectors-negative300.bin'\n",
    "print(\"Path to dataset files:\", path)\n",
    "      \n",
    "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "embedding_dim = 300\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[i] = word2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427f79c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:59.159303Z",
     "iopub.status.busy": "2025-06-22T16:46:59.159030Z",
     "iopub.status.idle": "2025-06-22T16:46:59.164483Z",
     "shell.execute_reply": "2025-06-22T16:46:59.163751Z"
    },
    "papermill": {
     "duration": 0.011034,
     "end_time": "2025-06-22T16:46:59.165783",
     "exception": false,
     "start_time": "2025-06-22T16:46:59.154749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23350, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220d36af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:59.173449Z",
     "iopub.status.busy": "2025-06-22T16:46:59.173168Z",
     "iopub.status.idle": "2025-06-22T16:46:59.227165Z",
     "shell.execute_reply": "2025-06-22T16:46:59.226258Z"
    },
    "papermill": {
     "duration": 0.059363,
     "end_time": "2025-06-22T16:46:59.228552",
     "exception": false,
     "start_time": "2025-06-22T16:46:59.169189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build LSTM Attention Sentiment Classifier\n",
    "# Define the attention layer\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.u = None\n",
    "        self.b = None\n",
    "        self.W = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable weights for attention mechanism\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        self.u = self.add_weight(name=\"att_u\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Score computation\n",
    "        v = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        vu = tf.tensordot(v, self.u, axes=1)\n",
    "        alphas = tf.nn.softmax(vu)\n",
    "\n",
    "        # Weighted sum of input\n",
    "        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), axis=1)\n",
    "        return output, alphas\n",
    "\n",
    "# Sample Bi-LSTM model with Attention\n",
    "def create_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_len,\n",
    "        trainable=False)(inputs)\n",
    "\n",
    "    # Bi-LSTM layer\n",
    "    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
    "\n",
    "    # Add Attention layer\n",
    "    attention_out, attention_weights = AttentionLayer()(lstm_out)\n",
    "\n",
    "    reshaped = Lambda(lambda x: tf.expand_dims(x, axis=1))(attention_out)  # (batch, 1, features)\n",
    "\n",
    "    # LSTM  layer post attention\n",
    "    lstm_after_attn = LSTM(64, return_sequences=False)(reshaped)\n",
    "\n",
    "    # flatten layer\n",
    "    dense = Dense(128, activation='relu')(lstm_after_attn)\n",
    "\n",
    "    # Final Dense layer\n",
    "    outputs = Dense(3, activation='softmax')(dense)\n",
    "\n",
    "    # Define the model\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c2f67d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:59.236328Z",
     "iopub.status.busy": "2025-06-22T16:46:59.236064Z",
     "iopub.status.idle": "2025-06-22T16:46:59.601427Z",
     "shell.execute_reply": "2025-06-22T16:46:59.600602Z"
    },
    "papermill": {
     "duration": 0.370659,
     "end_time": "2025-06-22T16:46:59.602770",
     "exception": false,
     "start_time": "2025-06-22T16:46:59.232111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-06-22 16:46:59.244878: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,005,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ attention_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)]   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │       \u001b[38;5;34m7,005,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m186,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ attention_layer (\u001b[38;5;33mAttentionLayer\u001b[0m)     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)]   │          \u001b[38;5;34m16,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,266,635</span> (27.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,266,635\u001b[0m (27.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">261,635</span> (1022.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m261,635\u001b[0m (1022.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,005,000</span> (26.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,005,000\u001b[0m (26.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set input shape and compile the model\n",
    "input_shape = (50,)  # For example, sequence length = 100, features per step = 50\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f1c67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:46:59.612051Z",
     "iopub.status.busy": "2025-06-22T16:46:59.611734Z",
     "iopub.status.idle": "2025-06-22T17:16:05.961835Z",
     "shell.execute_reply": "2025-06-22T17:16:05.960885Z"
    },
    "papermill": {
     "duration": 1746.356227,
     "end_time": "2025-06-22T17:16:05.963262",
     "exception": false,
     "start_time": "2025-06-22T16:46:59.607035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.4280 - loss: 1.0632 - val_accuracy: 0.5425 - val_loss: 0.9203\n",
      "Epoch 2/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.5862 - loss: 0.8918 - val_accuracy: 0.6296 - val_loss: 0.8466\n",
      "Epoch 3/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 53ms/step - accuracy: 0.6389 - loss: 0.8186 - val_accuracy: 0.6380 - val_loss: 0.8260\n",
      "Epoch 4/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.6522 - loss: 0.7968 - val_accuracy: 0.6454 - val_loss: 0.8201\n",
      "Epoch 5/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.6737 - loss: 0.7698 - val_accuracy: 0.6405 - val_loss: 0.8603\n",
      "Epoch 6/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.6780 - loss: 0.7523 - val_accuracy: 0.6478 - val_loss: 0.8160\n",
      "Epoch 7/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.6908 - loss: 0.7239 - val_accuracy: 0.6422 - val_loss: 0.8309\n",
      "Epoch 8/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7057 - loss: 0.6980 - val_accuracy: 0.6422 - val_loss: 0.8336\n",
      "Epoch 9/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7174 - loss: 0.6719 - val_accuracy: 0.6431 - val_loss: 0.8370\n",
      "Epoch 10/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7291 - loss: 0.6507 - val_accuracy: 0.6407 - val_loss: 0.8549\n",
      "Epoch 11/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7362 - loss: 0.6288 - val_accuracy: 0.6327 - val_loss: 0.8756\n",
      "Epoch 12/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.7530 - loss: 0.5982 - val_accuracy: 0.6269 - val_loss: 0.8943\n",
      "Epoch 13/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.7666 - loss: 0.5733 - val_accuracy: 0.6253 - val_loss: 0.9682\n",
      "Epoch 14/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.7793 - loss: 0.5489 - val_accuracy: 0.6220 - val_loss: 0.9651\n",
      "Epoch 15/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.7913 - loss: 0.5179 - val_accuracy: 0.6278 - val_loss: 1.0369\n",
      "Epoch 16/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.8109 - loss: 0.4798 - val_accuracy: 0.6322 - val_loss: 1.1151\n",
      "Epoch 17/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.8191 - loss: 0.4615 - val_accuracy: 0.6185 - val_loss: 1.1156\n",
      "Epoch 18/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.8269 - loss: 0.4414 - val_accuracy: 0.6249 - val_loss: 1.2898\n",
      "Epoch 19/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.8418 - loss: 0.4161 - val_accuracy: 0.6191 - val_loss: 1.3237\n",
      "Epoch 20/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.8567 - loss: 0.3780 - val_accuracy: 0.6187 - val_loss: 1.3359\n",
      "Epoch 21/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.8660 - loss: 0.3592 - val_accuracy: 0.6120 - val_loss: 1.4042\n",
      "Epoch 22/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.8708 - loss: 0.3436 - val_accuracy: 0.6127 - val_loss: 1.4673\n",
      "Epoch 23/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.8789 - loss: 0.3293 - val_accuracy: 0.6125 - val_loss: 1.5491\n",
      "Epoch 24/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.8937 - loss: 0.2930 - val_accuracy: 0.6145 - val_loss: 1.6204\n",
      "Epoch 25/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.8945 - loss: 0.2857 - val_accuracy: 0.6083 - val_loss: 1.6627\n",
      "Epoch 26/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9046 - loss: 0.2654 - val_accuracy: 0.6107 - val_loss: 1.7961\n",
      "Epoch 27/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9095 - loss: 0.2526 - val_accuracy: 0.6076 - val_loss: 1.8899\n",
      "Epoch 28/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9163 - loss: 0.2352 - val_accuracy: 0.6145 - val_loss: 2.0194\n",
      "Epoch 29/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 54ms/step - accuracy: 0.9265 - loss: 0.2132 - val_accuracy: 0.6016 - val_loss: 2.0844\n",
      "Epoch 30/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 52ms/step - accuracy: 0.9275 - loss: 0.2032 - val_accuracy: 0.6058 - val_loss: 2.2878\n",
      "Epoch 31/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9261 - loss: 0.2072 - val_accuracy: 0.6194 - val_loss: 2.2498\n",
      "Epoch 32/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9348 - loss: 0.1915 - val_accuracy: 0.6089 - val_loss: 2.2739\n",
      "Epoch 33/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9410 - loss: 0.1731 - val_accuracy: 0.6012 - val_loss: 2.1598\n",
      "Epoch 34/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9434 - loss: 0.1662 - val_accuracy: 0.6045 - val_loss: 2.3640\n",
      "Epoch 35/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 53ms/step - accuracy: 0.9476 - loss: 0.1506 - val_accuracy: 0.6080 - val_loss: 2.4342\n",
      "Epoch 36/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.9489 - loss: 0.1501 - val_accuracy: 0.6145 - val_loss: 2.6177\n",
      "Epoch 37/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9548 - loss: 0.1349 - val_accuracy: 0.6040 - val_loss: 2.6015\n",
      "Epoch 38/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.9582 - loss: 0.1255 - val_accuracy: 0.6098 - val_loss: 2.7494\n",
      "Epoch 39/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 51ms/step - accuracy: 0.9591 - loss: 0.1244 - val_accuracy: 0.6149 - val_loss: 2.8092\n",
      "Epoch 40/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.9571 - loss: 0.1272 - val_accuracy: 0.6112 - val_loss: 2.7961\n",
      "Epoch 41/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9657 - loss: 0.1024 - val_accuracy: 0.5994 - val_loss: 2.8689\n",
      "Epoch 42/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9658 - loss: 0.1045 - val_accuracy: 0.6067 - val_loss: 2.9750\n",
      "Epoch 43/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9689 - loss: 0.0918 - val_accuracy: 0.5987 - val_loss: 3.1981\n",
      "Epoch 44/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9659 - loss: 0.1009 - val_accuracy: 0.5929 - val_loss: 3.1088\n",
      "Epoch 45/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9725 - loss: 0.0837 - val_accuracy: 0.5996 - val_loss: 3.2599\n",
      "Epoch 46/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9772 - loss: 0.0734 - val_accuracy: 0.6014 - val_loss: 3.4960\n",
      "Epoch 47/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9751 - loss: 0.0761 - val_accuracy: 0.6058 - val_loss: 3.2036\n",
      "Epoch 48/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.9737 - loss: 0.0807 - val_accuracy: 0.6100 - val_loss: 3.2965\n",
      "Epoch 49/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9782 - loss: 0.0718 - val_accuracy: 0.5965 - val_loss: 3.2837\n",
      "Epoch 50/50\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 50ms/step - accuracy: 0.9808 - loss: 0.0635 - val_accuracy: 0.6085 - val_loss: 3.5327\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.6195 - loss: 3.2669\n",
      "Test Accuracy: 61.06%\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_train_pad, np.array(y_train_cat), epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Test Model\n",
    "loss, accuracy = model.evaluate(X_test_pad, np.array(y_test_cat))\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6763,
     "sourceId": 9801,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 989445,
     "sourceId": 1808590,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1391881,
     "sourceId": 2307650,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1905.058901,
   "end_time": "2025-06-22T17:16:09.721339",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T16:44:24.662438",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
